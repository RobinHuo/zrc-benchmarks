{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import enum\n",
    "\n",
    "_SciPyMetrics = ['braycurtis', 'canberra', 'chebyshev', 'cityblock', 'correlation', 'cosine', 'dice',\n",
    "                 'euclidean', 'hamming', 'jaccard', 'jensenshannon', 'kulczynski1', 'mahalanobis',\n",
    "                 'matching', 'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean',\n",
    "                 'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule']\n",
    "\n",
    "# Enumeration of metrics used for semantics benchmark\n",
    "SemanticMetrics = enum.Enum('SemanticMetrics', {f\"{k}\": k for k in _SciPyMetrics})\n",
    "\n",
    "\n",
    "# class SemanticMetrics(str, enum.Enum):\n",
    "#     def __new__(cls, label, benchmark, submission, parameters):\n",
    "#         obj = str.__new__(cls, [label])\n",
    "#         obj._value_ = label\n",
    "#         obj.benchmark = benchmark\n",
    "#         obj.submission = submission\n",
    "#         obj.parameters = parameters\n",
    "#         return obj\n",
    "\n",
    "\n",
    "# class SemanticMetricMeta(enum.EnumMeta):\n",
    "#\n",
    "#     def __new__(mcs, cls, bases, classdict):\n",
    "#         data = classdict['data']\n",
    "#         temp = type(classdict)()\n",
    "#         for metric in data:\n",
    "#             temp\n",
    "#\n",
    "#         return super(SemanticMetricMeta, mcs).__new__(mcs, cls, bases, temp)\n",
    "#\n",
    "#\n",
    "# class SemanticMetrics(str, enum.Enum, metaclass=SemanticMetricMeta):\n",
    "#     data = _SciPyMetrics\n",
    "#\n",
    "#     @classmethod\n",
    "#     def choices(cls):\n",
    "#         return ((member.value, name) for name, member in cls.__members__.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<enum 'SemanticMetrics'>\n",
      "SemanticMetrics.euclidean\n",
      "euclidean\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "f = SemanticMetrics('euclidean')\n",
    "print(type(f))\n",
    "print(f)\n",
    "print(f.value)\n",
    "print(type(f.value))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"test\": {\n",
      "        \"value\": \"euclidean\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class Testing(BaseModel):\n",
    "    value: SemanticMetrics = SemanticMetrics('euclidean')\n",
    "\n",
    "\n",
    "class Embedded(BaseModel):\n",
    "    test: Testing = Testing()\n",
    "\n",
    "\n",
    "t = Embedded()\n",
    "print(t.json(indent=4))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: APP_DIR=test_data\n",
      "{\n",
      "    \"lexical\": {\n",
      "        \"by_pair\": true,\n",
      "        \"by_length\": true,\n",
      "        \"by_frequency\": true,\n",
      "        \"result_filenames\": {\n",
      "            \"dev\": {\n",
      "                \"by_pair\": \"score_lexical_dev_by_pair.csv\",\n",
      "                \"by_frequency\": \"score_lexical_dev_by_frequency.csv\",\n",
      "                \"by_length\": \"score_lexical_dev_by_length.csv\"\n",
      "            },\n",
      "            \"test\": {\n",
      "                \"by_pair\": \"score_lexical_test_by_pair.csv\",\n",
      "                \"by_frequency\": \"score_lexical_test_by_frequency.csv\",\n",
      "                \"by_length\": \"score_lexical_test_by_length.csv\"\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \"syntactic\": {\n",
      "        \"result_filenames\": {\n",
      "            \"dev\": {\n",
      "                \"by_pair\": \"score_syntactic_dev_by_pair.csv\",\n",
      "                \"by_type\": \"score_syntactic_dev_by_type.csv\"\n",
      "            },\n",
      "            \"test\": {\n",
      "                \"by_pair\": \"score_syntactic_test_by_pair.csv\",\n",
      "                \"by_type\": \"score_syntactic_test_by_type.csv\"\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \"semantic\": {\n",
      "        \"metric\": \"euclidean\",\n",
      "        \"pooling\": \"mean\",\n",
      "        \"synthetic\": true,\n",
      "        \"librispeech\": true,\n",
      "        \"correlations\": true,\n",
      "        \"n_jobs\": 1,\n",
      "        \"result_filenames\": {\n",
      "            \"dev\": {\n",
      "                \"pairs\": \"score_semantic_dev_pairs.csv\",\n",
      "                \"correlations\": \"score_semantic_dev_correlation.csv\"\n",
      "            },\n",
      "            \"test\": {\n",
      "                \"pairs\": \"score_semantic_test_pairs.csv\",\n",
      "                \"correlations\": \"score_semantic_test_correlation.csv\"\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%env APP_DIR=test_data\n",
    "from zerospeech.benchmarks.sLM_21.params import SLM21BenchmarkParameters\n",
    "\n",
    "params = SLM21BenchmarkParameters()\n",
    "\n",
    "print(params.json(indent=4))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: APP_DIR=test_data\n"
     ]
    },
    {
     "data": {
      "text/plain": "['sLM21']"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%env APP_DIR=test_data\n",
    "import enum\n",
    "from zerospeech.benchmarks import sLM_21\n",
    "\n",
    "\n",
    "class BenchmarkList(str, enum.Enum):\n",
    "    def __new__(cls, label, benchmark, submission, parameters):\n",
    "        obj = str.__new__(cls, label)\n",
    "        obj._value_ = label\n",
    "        obj.benchmark = benchmark\n",
    "        obj.submission = submission\n",
    "        obj.parameters = parameters\n",
    "        return obj\n",
    "\n",
    "    sLM21 = 'sLM21', sLM_21.SLM21Benchmark, sLM_21.SLM21Submission, sLM_21.SLM21BenchmarkParameters\n",
    "\n",
    "\n",
    "[f.value for f in BenchmarkList]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}