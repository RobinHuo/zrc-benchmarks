{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: APP_DIR=/data/zerospeech/zrbench\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%env APP_DIR=/data/zerospeech/zrbench\n",
    "from pathlib import Path\n",
    "\n",
    "from zerospeech.benchmarks.sLM_21 import SLM21Submission\n",
    "\n",
    "submission = SLM21Submission.load(Path('/data/zerospeech/zrbench/samples/sLM21-random-submission'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "%env APP_DIR=/data/zerospeech/zrbench\n",
    "from pathlib import Path\n",
    "\n",
    "from zerospeech.benchmarks.abx_LS import AbxLSSubmission\n",
    "\n",
    "submission = AbxLSSubmission.load(Path('/data/zerospeech/zrbench/samples/abxLS-random-submission/'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: APP_DIR=/data/zerospeech/zrbench\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%env APP_DIR=/data/zerospeech/zrbench\n",
    "submission.valid"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: APP_DIR=/data/zerospeech/zrbench\n"
     ]
    }
   ],
   "source": [
    "%env APP_DIR=/data/zerospeech/zrbench\n",
    "from pathlib import Path\n",
    "from zerospeech.benchmarks.sLM_21 import SLM21Submission\n",
    "from zerospeech.benchmarks.sLM_21.validators import SLM21SubmissionValidator\n",
    "\n",
    "submission = SLM21Submission.load(Path('/data/zerospeech/zrbench/samples/sLM21-random-submission'))\n",
    "\n",
    "validator = SLM21SubmissionValidator()\n",
    "\n",
    "res = validator.validate(submission)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: APP_DIR=/data/zerospeech/zrbench\n",
      "ValidationOK(lexical_dev): dataframe validates tests\n",
      "ValidationOK(lexical_dev): expected files found\n",
      "ValidationOK(lexical_test): dataframe validates tests\n",
      "ValidationOK(lexical_test): expected files found\n"
     ]
    }
   ],
   "source": [
    "%env APP_DIR=/data/zerospeech/zrbench\n",
    "\n",
    "for r in res:\n",
    "    print(r)\n",
    "#\n",
    "# print('-'*20)\n",
    "# print(f\"{str(res[1])} -> {len(res[1].data)}\")\n",
    "# print(len(validator.dataset.index.subsets.lexical_dev.items.wav_list.files_list))\n",
    "# print('-'*20)\n",
    "# # print(res[1].data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import abc\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "class SubmissionBase(abc.ABC):\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def submission_valid(self, quiet: bool = False) -> bool:\n",
    "        pass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SubmissionX(SubmissionBase):\n",
    "    a: int\n",
    "    b: float\n",
    "    c: str\n",
    "\n",
    "    def submission_valid(self, quiet: bool = False) -> bool:\n",
    "        condition = (self.a > 10) and (0 < self.b <= 20.5)\n",
    "        if not quiet:\n",
    "            if condition:\n",
    "                print(\"submission is valid !!!\")\n",
    "            else:\n",
    "                print(\"submission is not valid !!!\")\n",
    "\n",
    "        return condition\n",
    "\n",
    "\n",
    "test = SubmissionX(a=1234, b=12.3, c=\"other\")\n",
    "test.submission_valid()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "Field name \"submission_valid\" shadows a BaseModel attribute; use a different field name with \"alias='submission_valid'\".",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [4]\u001B[0m, in \u001B[0;36m<cell line: 13>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      7\u001B[0m     \u001B[38;5;129m@abc\u001B[39m\u001B[38;5;241m.\u001B[39mabstractmethod\n\u001B[1;32m      8\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msubmission_valid\u001B[39m(\u001B[38;5;28mself\u001B[39m, quiet: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mbool\u001B[39m:\n\u001B[1;32m      9\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[0;32m---> 13\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mSubmissionX\u001B[39;00m(SubmissionBase):\n\u001B[1;32m     14\u001B[0m     a: \u001B[38;5;28mint\u001B[39m\n\u001B[1;32m     15\u001B[0m     b : \u001B[38;5;28mfloat\u001B[39m\n",
      "File \u001B[0;32m~/.local/lib/pyenv/versions/zr-bench/lib/python3.9/site-packages/pydantic/main.py:228\u001B[0m, in \u001B[0;36mpydantic.main.ModelMetaclass.__new__\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/.local/lib/pyenv/versions/zr-bench/lib/python3.9/site-packages/pydantic/utils.py:163\u001B[0m, in \u001B[0;36mpydantic.utils.validate_field_name\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: Field name \"submission_valid\" shadows a BaseModel attribute; use a different field name with \"alias='submission_valid'\"."
     ]
    }
   ],
   "source": [
    "import abc\n",
    "import functools\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class SubmissionBase(BaseModel, abc.ABC):\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def submission_valid(self, quiet: bool = False) -> bool:\n",
    "        pass\n",
    "\n",
    "\n",
    "class SubmissionX(SubmissionBase):\n",
    "    a: int\n",
    "    b : float\n",
    "    c: str\n",
    "\n",
    "    @functools.lru_cache\n",
    "    def submission_valid(self, quiet: bool = False) -> bool:\n",
    "        condition = (self.a > 10) and (0 < self.b <= 20.5)\n",
    "        if condition and not quiet:\n",
    "            print(\"submission is not valid !!!\")\n",
    "        return condition\n",
    "\n",
    "test = SubmissionX(a=1234, b=12.3, c=\"other\")\n",
    "test.submission_valid()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found error 2\n",
      "found error 2\n",
      "found error 2\n",
      "found error 2\n",
      "found error 2\n",
      "found error 2\n",
      "found error 2\n",
      "found error 2\n",
      "found error 2\n",
      "found error 2\n",
      "found error 2\n",
      "found error 2\n",
      "found error 2\n",
      "found error 2\n",
      "found error 2\n",
      "found error 2\n",
      "found error 2\n",
      "found error 2\n",
      "found error 2\n",
      "found error 2\n",
      "found error 2\n",
      "found error 2\n",
      "found error 2\n",
      "found error 2\n",
      "found error 2\n",
      "found error 2\n",
      "found error 2\n",
      "found error 2\n",
      "found error 2\n",
      "found error 2\n",
      "found error 2\n",
      "[]\n",
      "['error', 'error', 'error', 'error', 'error', 'error', 'error', 'error', 'error', 'error', 'error', 'error', 'error', 'error', 'error', 'error', 'error', 'error', 'error', 'error', 'error', 'error', 'error', 'error', 'error', 'error', 'error', 'error', 'error', 'error', 'error']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def length_comparison(dim: int):\n",
    "    data = dict(ncols=[], col_len=1)\n",
    "\n",
    "    def comparison(array: List[str]):\n",
    "        data['ncols'].append(len(array))\n",
    "        res = []\n",
    "\n",
    "        if len(set(data['ncols'])) != 1:\n",
    "            print(f\"found error {len(set(data['ncols']))}\")\n",
    "            res = ['error']\n",
    "        return res\n",
    "\n",
    "    return comparison\n",
    "\n",
    "\n",
    "test_1 = [[random.randint(1, 30) for _ in range(100)] for _ in range(50)]\n",
    "test_2 = [[random.randint(1, 30) for _ in range(100)] for _ in range(50)]\n",
    "\n",
    "# add two at random\n",
    "test_2[29].append(random.randint(1, 30))\n",
    "test_2[19].append(random.randint(1, 30))\n",
    "\n",
    "comp1 = length_comparison(2)\n",
    "comp2 = length_comparison(2)\n",
    "\n",
    "results1 = []\n",
    "results2 = []\n",
    "for i1, i2 in zip(test_1, test_2):\n",
    "    results1.extend(comp1(i1))\n",
    "    results2.extend(comp2(i2))\n",
    "\n",
    "print(results1)\n",
    "print(results2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}